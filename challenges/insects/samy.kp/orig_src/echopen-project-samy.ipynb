{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Insects classification\"\n",
    "authors:\n",
    "- Samy\n",
    "tags:\n",
    "- RAMP\n",
    "- ConvNets\n",
    "- Challenge\n",
    "created_at: 2016-11-08\n",
    "updated_at: 2016-11-08\n",
    "tldr: \n",
    "    Insect classification challenge\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pollenating Insects classification - Samy Blusseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "### 1) Setting up the working environment\n",
    "To address the assigned task, I downloaded the necessary files (data, starting kit) and installed helpful software (Jupyter, TensorFlow, Theano, Keras).\n",
    "\n",
    "\n",
    "### 2) Documentation\n",
    "I learnt the very basics of Convolutional Neural Networks on a Standford course website (http://vision.stanford.edu/teaching/cs231n/syllabus.html) for which the corresponding videos can be found here http://academictorrents.com/details/46c5af9e2075d9af06f280b55b65cf9b44eb9fe7/collections.\n",
    "\n",
    "To get started with Keras, I relied on Keras Documentation and on this tutorial http://online.cambridgecoding.com/notebooks/cca_admin/convolutional-neural-networks-with-keras.\n",
    "\n",
    "\n",
    "### 3) Strategy\n",
    "Quite soon I realized that I would need more time to come up with an interesting solution the problem. Not only my knowledge and experience of CNNs are very limited, but testing different architectures and monitoring the training in order to find the right strategy also take long.\n",
    "\n",
    "Therefore I decided to implement a very simple CNN, inspired at examples I found in the above references. The justification for the chosen architecture is that it seems to follow some common and good practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = np.load(\"train_64x64.npz\")\n",
    "X, y = data['X'], data['y'] # X contains the images, y the labels\n",
    "\n",
    "# Split data into training and test sets\n",
    "# We checked that the 18 classes were roughly equally represented in both sets\n",
    "num_train=18000 # 18000 training examples\n",
    "X_train = X[0:num_train, :, :, :]\n",
    "y_train = y[0:num_train]\n",
    "X_test = X[num_train:, :, :, :]\n",
    "y_test = y[num_train:]\n",
    "\n",
    "depth, height, width = X_train.shape[1:4] # size of the data\n",
    "num_test = X_test.shape[0] # number of test examples\n",
    "class_id = np.unique(y_train) # the numerical class labels\n",
    "num_classes = class_id.shape[0] # the number of insect classes\n",
    "\n",
    "# Convert the original numerical class labels into their indexes from 0 to num_classes\n",
    "cv_dict = dict()\n",
    "for i in range(0, len(class_id)):\n",
    "    cv_dict[str(class_id[i])] = i\n",
    "y_train2 = np.zeros(y_train.shape)\n",
    "for i in range(len(y_train2)):\n",
    "    y_train2[i] = int(cv_dict[str(y_train[i])])\n",
    "y_test2 = np.zeros(y_test.shape)\n",
    "for i in range(len(y_test2)):\n",
    "    y_test2[i] = int(cv_dict[str(y_test[i])])\n",
    "    \n",
    "    \n",
    "# Pre-process training and test sets\n",
    "X_train = (X_train / 255.)\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "X_test = (X_test / 255.)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train2, num_classes) # One-hot encode the labels\n",
    "Y_train =Y_train.astype(np.float32)\n",
    "\n",
    "Y_test = np_utils.to_categorical(y_test2, num_classes) # One-hot encode the labels\n",
    "Y_test =Y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------#\n",
    "#----------------------------- MODEL -------------------------------------#\n",
    "#-------------------------------------------------------------------------#\n",
    "\n",
    "# CNN parameters\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "kernel_size = 3 #  3x3 filters\n",
    "pool_sz = 2 # 2x2 pooling\n",
    "conv_depth_1 = 32 # 32 kernels for the first two convolutional layers\n",
    "conv_depth_2 = 64 # 64 kernels for the last two convolutional layers\n",
    "drop_prob_1 = 0.25 # dropout probability after the convolutional layers\n",
    "drop_prob_2 = 0.5 # dropout probability after the fully connected layer\n",
    "hidden_size = 512 # the FC layer will have 512 neurons\n",
    "\n",
    "# Layers\n",
    "model = Sequential()\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "model.add(Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', input_shape=(depth, height, width)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_sz, pool_sz)))\n",
    "model.add(Dropout(drop_prob_1))\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "model.add(Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_sz, pool_sz)))\n",
    "model.add(Dropout(drop_prob_1))\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(drop_prob_2))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Save model\n",
    "json_string = model.to_json()\n",
    "fid = open('model.json', 'w')\n",
    "fid.write(json_string)\n",
    "fid.close\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "          batch_size=batch_size, nb_epoch=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "\n",
    "# Fit model on training set\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=num_epochs,\n",
    "          verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "\n",
    "# Evaluate model on test set\n",
    "score=model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(score)\n",
    "\n",
    "# Save weights\n",
    "model.save_weights('model_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This piece of code is meant to load the just trained model and its weights, and evaluate it\n",
    "# For it to work, X_test and Y_test need to be defined\n",
    "\n",
    "# Load model\n",
    "fid = open('model.json', 'r')\n",
    "json_string = fid.read()\n",
    "fid.close()\n",
    "\n",
    "# Load weights\n",
    "model.load_weights('model_weights.hdf5', by_name=False)\n",
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "# Evaluate model\n",
    "score=model.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set\n",
    "print(score)\n",
    "\n",
    "# Predicted classes\n",
    "classes = model.predict_classes(X_test, verbose=1)\n",
    "ind = np.where(classes > 0) # indices of samples which were not labeled Apis mellifera\n",
    "print(ind) # Empty tuple: all samples were labeled Apis mellifera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The accuracy of the model is about 29%. This is very low, but what is more worrying is that along training the loss decreased very slowly and the training accuracy remained constant after the second epoch.\n",
    "\n",
    "These clues made me suspect that one of the problems may be the over-representation of the first class in the data set. Indeed, the accuracy is roughly equal to the proportion of Apis mellifera in the data set, as if the network had been trained to the detecttion of that class only.\n",
    "\n",
    "I checked the predicted classes of the test set (see code here above), and as suspected all the samples were assigned the Apis mellifera class. I am not sure if this is due to the structure of the data or to a bug in my implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I would do next\n",
    "\n",
    "The most urgent task is to figure out if there is a bug in the code causing the classification of all samples into the first class. A simple thing to try would be build a training set with uniform representation of classes. This would mean a much smaller training set, but should help spot a bug.\n",
    "\n",
    "If not, then different architectures should be tested.\n",
    "To that aim, I would try and follow an advice I read in the previously mentionned references: \n",
    "- download a pre-trained model that already prooved high accuracy in image classification (ImageNet?)\n",
    "- perform fine tuning of that model, that is, further optimize its parameters to the present specific task.\n",
    "\n",
    "If no architecture shows improvement, then it might be relevant to change the structure of the training data set, so that no class be as over represented as Apis mellifera so far.\n",
    "\n",
    "Furthermore, I would spend more time understanding the methods that help make the right architectural choices.\n",
    "Finally, speeding up the training, by running it on GPU, seems necessary so that more variations can be tested. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "0px",
    "width": "0px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}